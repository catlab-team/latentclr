{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# change json file to try different models\n",
    "JSON_PATH = \"configs/stylegan2_ffhq.json\"\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    CONFIG_JSON = json.load(f)\n",
    "    \n",
    "MODEL_DIR = CONFIG_JSON[\"MODEL_DIR\"]\n",
    "DIRECTIONS = CONFIG_JSON[\"DIRECTIONS\"]\n",
    "LAYER_MAPS = CONFIG_JSON[\"LAYER_MAPS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'_target_': 'colat.models.NonlinearConditional', 'normalize': True, 'alpha': 0.1, 'depth': 1, 'size': 512}, 'loss': {'_target_': 'colat.loss.ContrastiveLoss', 'temp': 0.5, 'abs': True, 'reduce': 'mean'}, 'generator': {'_target_': 'colat.generators.StyleGAN2Generator', 'device': 'cuda', 'truncation': 0.7, 'class_name': 'ffhq', 'use_w': True, 'feature_layer': 'conv1'}, 'projector': {'_target_': 'colat.projectors.IdentityProjector', 'normalize': True}, 'hparams': {'batch_size': 8, 'iterations': 10000, 'grad_clip_max_norm': None, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.MultiStepLR', 'milestones': [1000, 5000], 'gamma': 0.2}, 'iteration': 3000}, 'checkpoint': None, 'tensorboard': True, 'auto_cpu_if_no_gpu': True, 'device': 'cuda:0', 'mixed_precision': False, 'save': True, 'eval_freq': 1000, 'eval_iters': 100, 'k': 100, 'train_projector': True}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "conf_path = os.path.join(MODEL_DIR, \"config.yaml\")\n",
    "model_path = os.path.join(MODEL_DIR, \"model.pt\")\n",
    "\n",
    "# load and print config\n",
    "cfg = yaml.load(open(conf_path), Loader=yaml.FullLoader)\n",
    "cfg = OmegaConf.create(cfg)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StyleGAN2: Optimized CUDA op FusedLeakyReLU not available, using native PyTorch fallback.\n",
      "StyleGAN2: Optimized CUDA op UpFirDn2d not available, using native PyTorch fallback.\n"
     ]
    },
    {
     "ename": "HydraException",
     "evalue": "Error calling 'colat.projectors.IdentityProjector' : Encountered error: `cannot import name 'Projector' from 'colat.projectors' (../colat/projectors/__init__.py)` when loading module 'colat.projectors.IdentityProjector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                 \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/projects/latentclr/colat/projectors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIdentityProjector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearProjector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNonlinearProjector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/latentclr/colat/projectors/identity.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProjector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Projector' from 'colat.projectors' (../colat/projectors/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/site-packages/hydra/utils.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cls_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtype_or_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_locate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_or_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/site-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0;34mf\"Encountered error: `{e}` when loading module '{path}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m                 ) from e\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Encountered error: `cannot import name 'Projector' from 'colat.projectors' (../colat/projectors/__init__.py)` when loading module 'colat.projectors.IdentityProjector'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHydraException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_104418/2755356415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprojector\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# preload models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latentclr-env/lib/python3.7/site-packages/hydra/utils.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHydraException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error calling '{cls}' : {e}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHydraException\u001b[0m: Error calling 'colat.projectors.IdentityProjector' : Encountered error: `cannot import name 'Projector' from 'colat.projectors' (../colat/projectors/__init__.py)` when loading module 'colat.projectors.IdentityProjector'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from hydra.utils import instantiate, to_absolute_path\n",
    "\n",
    "device = cfg.device\n",
    "\n",
    "# init models\n",
    "model: torch.nn.Module = instantiate(cfg.model, k=cfg.k).to(device);\n",
    "generator: torch.nn.Module = instantiate(cfg.generator).to(device);\n",
    "projector: torch.nn.Module = instantiate(cfg.projector).to(device);\n",
    "\n",
    "# preload models\n",
    "checkpoint_path = to_absolute_path(model_path);\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device);\n",
    "model.load_state_dict(checkpoint[\"model\"]);\n",
    "projector.load_state_dict(checkpoint[\"projector\"]);\n",
    "\n",
    "# set to eval\n",
    "model.eval();\n",
    "generator.eval();\n",
    "projector.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import math\n",
    "sign = lambda x: math.copysign(1, x)\n",
    "\n",
    "#  Helper function to edit latent codes\n",
    "def _edit(z, alpha, ks):\n",
    "    \"\"\"\n",
    "        z: latent code to edit\n",
    "        alpha: magnitude of the edit\n",
    "        ks: directions to apply\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #  check if only one latent code is given\n",
    "    assert z.shape[0] == 1 or z.shape[0] == len(\n",
    "        ks\n",
    "    ), \"Only able to apply all directions to single latent code or apply each direction to single code\"\n",
    "    model.alpha = alpha\n",
    "\n",
    "    # Apply Directions\n",
    "    zs = []\n",
    "    for i, k in enumerate(ks):\n",
    "        _i = i if z.shape[0] > 1 else 0\n",
    "        zs.append(model.forward_single(z[i : i + 1, ...], k=k))\n",
    "    zs = torch.cat(zs, dim=0)\n",
    "    return zs\n",
    "\n",
    "# Helper function to generate images\n",
    "def _generate(zs, z=None, feed_layers=None):\n",
    "    \"\"\"\n",
    "        zs: z codes to feed into generator\n",
    "        z: original z code\n",
    "        feed_layers: targeted edit layers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Manipulate only asked layers\n",
    "    if feed_layers is not None and z is not None:\n",
    "        n_latent = generator.n_latent()\n",
    "\n",
    "        zs_layers = []\n",
    "        for i in range(n_latent):\n",
    "            if i in feed_layers:\n",
    "                zs_layers.append(zs)\n",
    "            else:\n",
    "                zs_layers.append(z.expand(zs.shape[0], -1))\n",
    "        zs = zs_layers\n",
    "\n",
    "    return generator(zs).detach().cpu()\n",
    "\n",
    "# Visualizes images\n",
    "def visualize(\n",
    "    dir_ids,\n",
    "    feed_layers,\n",
    "    alphas=[-9,-6,-3,0,3,6,9],\n",
    "    feat_name=None,\n",
    "    seeds=[0],\n",
    "    iterative=False,\n",
    "    scale=5,\n",
    "):\n",
    "    # process alphas\n",
    "    alphas = sorted(alphas)\n",
    "    i = 0\n",
    "    while alphas[i] < 0:\n",
    "        i += 1\n",
    "    neg_alphas = alphas[:i]\n",
    "\n",
    "    if alphas[i] == 0:\n",
    "        i += 1\n",
    "    pos_alphas = alphas[i:]\n",
    "    \n",
    "    \n",
    "    for seed in seeds:\n",
    "        # set seed\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # generate latent code\n",
    "        z = generator.sample_latent(1)\n",
    "        z = z.to(device)\n",
    "    \n",
    "\n",
    "        with torch.no_grad():\n",
    "            # get original image\n",
    "            orj_img = _generate(z)\n",
    "\n",
    "            # images container\n",
    "            images = []\n",
    "\n",
    "            #  start with z and alpha = 0\n",
    "            z_orig = z\n",
    "            prev_alpha = 0\n",
    "            for alpha in reversed(neg_alphas):\n",
    "                #  if iterative use last z and d(alpha)\n",
    "                _z = z if iterative else z_orig\n",
    "                _alpha = alpha - prev_alpha if iterative else alpha\n",
    "\n",
    "                z = _edit(_z, _alpha, ks=dir_ids)\n",
    "                images.append(_generate(z, z_orig, feed_layers=feed_layers))\n",
    "                prev_alpha = alpha\n",
    "\n",
    "            # reverse images\n",
    "            images = list(reversed(images))\n",
    "\n",
    "            # reset z and alpha\n",
    "            z = z_orig\n",
    "            prev_alpha = 0\n",
    "            for alpha in pos_alphas:\n",
    "                #  if iterative use last z and d(alpha)\n",
    "                _z = z if iterative else z_orig\n",
    "                _alpha = alpha - prev_alpha if iterative else alpha\n",
    "\n",
    "                z = _edit(_z, _alpha, ks=dir_ids)\n",
    "                images.append(_generate(z, z_orig,feed_layers=feed_layers))\n",
    "                prev_alpha = alpha\n",
    "\n",
    "            #  prepare final image\n",
    "            images = torch.stack(images, dim=0)\n",
    "            images = images.transpose(1, 0)\n",
    "            col_orj_img = orj_img.repeat((images.size(0), 1, 1, 1))\n",
    "\n",
    "            titles = []\n",
    "            before_sign = -1\n",
    "            imgs = []\n",
    "            for ind, alpha in enumerate(neg_alphas + pos_alphas):\n",
    "                # append orijinal image\n",
    "                if sign(alpha) != before_sign:\n",
    "                    imgs.append(col_orj_img)\n",
    "                    titles.append(\"α=0\")\n",
    "                    before_sign = sign(alpha)\n",
    "\n",
    "                titles.append(f\"α= {alpha:.3f}\")\n",
    "                imgs.append(images[:, ind, ...])\n",
    "            images = torch.stack(imgs).transpose(1, 0)\n",
    "            \n",
    "            images = images.transpose(2,3)\n",
    "            images = images.transpose(3,4)\n",
    "\n",
    "            fig, axs = plt.subplots(\n",
    "                nrows=images.shape[0],\n",
    "                ncols=images.shape[1],\n",
    "                figsize=(images.shape[1] * scale, images.shape[0] * scale))\n",
    "            axs = axs.reshape(images.shape[0], images.shape[1])\n",
    "\n",
    "            fig.suptitle(feat_name)\n",
    "            for i in range(images.shape[0]):\n",
    "                axs[i][0].set_ylabel(f\"k= {dir_ids[i]}\")\n",
    "                for j in range(images.shape[1]):\n",
    "                    axs[i][j].set_xlabel(titles[j])\n",
    "                    axs[i][j].set_xticks([])\n",
    "                    axs[i][j].set_yticks([])\n",
    "                    axs[i][j].imshow(images[i][j]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = list(DIRECTIONS.keys())\n",
    "\n",
    "print(\"Annotated features:\")\n",
    "print(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "feat_name = feat_list[random.randint(0, len(feat_list)-1)]\n",
    "\n",
    "# read feature\n",
    "dir_id = DIRECTIONS[feat_name][0]\n",
    "feed_layers = LAYER_MAPS[str(DIRECTIONS[feat_name][1])]\n",
    "alphas = DIRECTIONS[feat_name][2] if len(DIRECTIONS[feat_name]) > 2 else [-7,-5,-1,0,1,5,7]\n",
    "\n",
    "visualize(\n",
    "    dir_ids=[dir_id],\n",
    "    feed_layers=feed_layers,\n",
    "    feat_name=feat_name,\n",
    "    alphas=alphas,\n",
    "    seeds=[0,1]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LatentCLR",
   "language": "python",
   "name": "latentclr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
