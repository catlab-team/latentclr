{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# change json file to try different models\n",
    "JSON_PATH = \"configs/stylegan2_ffhq.json\"\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    CONFIG_JSON = json.load(f)\n",
    "    \n",
    "MODEL_DIR = CONFIG_JSON[\"MODEL_DIR\"]\n",
    "DIRECTIONS = CONFIG_JSON[\"DIRECTIONS\"]\n",
    "LAYER_MAPS = CONFIG_JSON[\"LAYER_MAPS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "conf_path = os.path.join(MODEL_DIR, \"config.yaml\")\n",
    "model_path = os.path.join(MODEL_DIR, \"model.pt\")\n",
    "\n",
    "# load and print config\n",
    "cfg = yaml.load(open(conf_path), Loader=yaml.FullLoader)\n",
    "cfg = OmegaConf.create(cfg)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from hydra.utils import instantiate, to_absolute_path\n",
    "\n",
    "device = cfg.device\n",
    "\n",
    "# init models\n",
    "model: torch.nn.Module = instantiate(cfg.model, k=cfg.k).to(device);\n",
    "generator: torch.nn.Module = instantiate(cfg.generator).to(device);\n",
    "projector: torch.nn.Module = instantiate(cfg.projector).to(device);\n",
    "\n",
    "# preload models\n",
    "checkpoint_path = to_absolute_path(model_path);\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device);\n",
    "model.load_state_dict(checkpoint[\"model\"]);\n",
    "projector.load_state_dict(checkpoint[\"projector\"]);\n",
    "\n",
    "# set to eval\n",
    "model.eval();\n",
    "generator.eval();\n",
    "projector.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import math\n",
    "sign = lambda x: math.copysign(1, x)\n",
    "\n",
    "#  Helper function to edit latent codes\n",
    "def _edit(z, alpha, ks):\n",
    "    \"\"\"\n",
    "        z: latent code to edit\n",
    "        alpha: magnitude of the edit\n",
    "        ks: directions to apply\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #  check if only one latent code is given\n",
    "    assert z.shape[0] == 1 or z.shape[0] == len(\n",
    "        ks\n",
    "    ), \"Only able to apply all directions to single latent code or apply each direction to single code\"\n",
    "    model.alpha = alpha\n",
    "\n",
    "    # Apply Directions\n",
    "    zs = []\n",
    "    for i, k in enumerate(ks):\n",
    "        _i = i if z.shape[0] > 1 else 0\n",
    "        zs.append(model.forward_single(z[i : i + 1, ...], k=k))\n",
    "    zs = torch.cat(zs, dim=0)\n",
    "    return zs\n",
    "\n",
    "# Helper function to generate images\n",
    "def _generate(zs, z=None, feed_layers=None):\n",
    "    \"\"\"\n",
    "        zs: z codes to feed into generator\n",
    "        z: original z code\n",
    "        feed_layers: targeted edit layers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Manipulate only asked layers\n",
    "    if feed_layers is not None and z is not None:\n",
    "        n_latent = generator.n_latent()\n",
    "\n",
    "        zs_layers = []\n",
    "        for i in range(n_latent):\n",
    "            if i in feed_layers:\n",
    "                zs_layers.append(zs)\n",
    "            else:\n",
    "                zs_layers.append(z.expand(zs.shape[0], -1))\n",
    "        zs = zs_layers\n",
    "\n",
    "    return generator(zs).detach().cpu()\n",
    "\n",
    "# Visualizes images\n",
    "def visualize(\n",
    "    dir_ids,\n",
    "    feed_layers,\n",
    "    alphas=[-9,-6,-3,0,3,6,9],\n",
    "    feat_name=None,\n",
    "    seeds=[0],\n",
    "    iterative=False,\n",
    "    scale=5,\n",
    "):\n",
    "    # process alphas\n",
    "    alphas = sorted(alphas)\n",
    "    i = 0\n",
    "    while alphas[i] < 0:\n",
    "        i += 1\n",
    "    neg_alphas = alphas[:i]\n",
    "\n",
    "    if alphas[i] == 0:\n",
    "        i += 1\n",
    "    pos_alphas = alphas[i:]\n",
    "    \n",
    "    \n",
    "    for seed in seeds:\n",
    "        # set seed\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # generate latent code\n",
    "        z = generator.sample_latent(1)\n",
    "        z = z.to(device)\n",
    "    \n",
    "\n",
    "        with torch.no_grad():\n",
    "            # get original image\n",
    "            orj_img = _generate(z)\n",
    "\n",
    "            # images container\n",
    "            images = []\n",
    "\n",
    "            #  start with z and alpha = 0\n",
    "            z_orig = z\n",
    "            prev_alpha = 0\n",
    "            for alpha in reversed(neg_alphas):\n",
    "                #  if iterative use last z and d(alpha)\n",
    "                _z = z if iterative else z_orig\n",
    "                _alpha = alpha - prev_alpha if iterative else alpha\n",
    "\n",
    "                z = _edit(_z, _alpha, ks=dir_ids)\n",
    "                images.append(_generate(z, z_orig, feed_layers=feed_layers))\n",
    "                prev_alpha = alpha\n",
    "\n",
    "            # reverse images\n",
    "            images = list(reversed(images))\n",
    "\n",
    "            # reset z and alpha\n",
    "            z = z_orig\n",
    "            prev_alpha = 0\n",
    "            for alpha in pos_alphas:\n",
    "                #  if iterative use last z and d(alpha)\n",
    "                _z = z if iterative else z_orig\n",
    "                _alpha = alpha - prev_alpha if iterative else alpha\n",
    "\n",
    "                z = _edit(_z, _alpha, ks=dir_ids)\n",
    "                images.append(_generate(z, z_orig,feed_layers=feed_layers))\n",
    "                prev_alpha = alpha\n",
    "\n",
    "            #  prepare final image\n",
    "            images = torch.stack(images, dim=0)\n",
    "            images = images.transpose(1, 0)\n",
    "            col_orj_img = orj_img.repeat((images.size(0), 1, 1, 1))\n",
    "\n",
    "            titles = []\n",
    "            before_sign = -1\n",
    "            imgs = []\n",
    "            for ind, alpha in enumerate(neg_alphas + pos_alphas):\n",
    "                # append orijinal image\n",
    "                if sign(alpha) != before_sign:\n",
    "                    imgs.append(col_orj_img)\n",
    "                    titles.append(\"α=0\")\n",
    "                    before_sign = sign(alpha)\n",
    "\n",
    "                titles.append(f\"α= {alpha:.3f}\")\n",
    "                imgs.append(images[:, ind, ...])\n",
    "            images = torch.stack(imgs).transpose(1, 0)\n",
    "            \n",
    "            images = images.transpose(2,3)\n",
    "            images = images.transpose(3,4)\n",
    "\n",
    "            fig, axs = plt.subplots(\n",
    "                nrows=images.shape[0],\n",
    "                ncols=images.shape[1],\n",
    "                figsize=(images.shape[1] * scale, images.shape[0] * scale))\n",
    "            axs = axs.reshape(images.shape[0], images.shape[1])\n",
    "\n",
    "            fig.suptitle(feat_name)\n",
    "            for i in range(images.shape[0]):\n",
    "                axs[i][0].set_ylabel(f\"k= {dir_ids[i]}\")\n",
    "                for j in range(images.shape[1]):\n",
    "                    axs[i][j].set_xlabel(titles[j])\n",
    "                    axs[i][j].set_xticks([])\n",
    "                    axs[i][j].set_yticks([])\n",
    "                    axs[i][j].imshow(images[i][j]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = list(DIRECTIONS.keys())\n",
    "\n",
    "print(\"Annotated features:\")\n",
    "print(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "feat_name = feat_list[random.randint(0, len(feat_list)-1)]\n",
    "\n",
    "# read feature\n",
    "dir_id = DIRECTIONS[feat_name][0]\n",
    "feed_layers = LAYER_MAPS[str(DIRECTIONS[feat_name][1])]\n",
    "alphas = DIRECTIONS[feat_name][2] if len(DIRECTIONS[feat_name]) > 2 else [-7,-5,-1,0,1,5,7]\n",
    "\n",
    "visualize(\n",
    "    dir_ids=[dir_id],\n",
    "    feed_layers=feed_layers,\n",
    "    feat_name=feat_name,\n",
    "    alphas=alphas,\n",
    "    seeds=[0,1]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd032c7ce05a1260c7981053a33f2a3b0055135387ebc0aa1ab9b7dffcae112d58d",
   "display_name": "Python 3.8.5 64-bit ('torch-1.6': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}